{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-2002 Data Project 1: E-Commerce Sales Analytics\n",
    "## ETL Pipeline for Dimensional Data Mart\n",
    "\n",
    "**Business Process:** Online Retail Sales Analysis\n",
    "\n",
    "### Dimensional Model:\n",
    "- **Fact Table:** `fact_sales`\n",
    "- **Dimension Tables:** `dim_date`, `dim_customer`, `dim_product`\n",
    "\n",
    "**Rest of Documentation at Bottom of the Page**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install pymysql pandas sqlalchemy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine, text\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'ecommerce_datamart' created or already exists.\n",
      "Database connection established successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DB_HOST = 'localhost' \n",
    "DB_USER = 'root'       \n",
    "DB_PASSWORD = 'Jh290917' \n",
    "DB_NAME = 'ecommerce_datamart'\n",
    "\n",
    "\n",
    "connection_string = f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}'\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    temp_engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}')\n",
    "    with temp_engine.connect() as conn:\n",
    "        conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {DB_NAME}\"))\n",
    "    print(f\"Database '{DB_NAME}' created or already exists.\")\n",
    "    \n",
    "    \n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"Database connection established successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample Source Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Source MySQL Database (Customer Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source database 'source_customer_db' created.\n",
      "Error creating source customer data: 'Connection' object has no attribute 'commit'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SOURCE_DB = 'source_customer_db'\n",
    "\n",
    "try:\n",
    "    temp_engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}')\n",
    "    with temp_engine.connect() as conn:\n",
    "        conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {SOURCE_DB}\"))\n",
    "    print(f\"Source database '{SOURCE_DB}' created.\")\n",
    "    \n",
    "    source_engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{SOURCE_DB}')\n",
    "    \n",
    "    \n",
    "    create_customer_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS customers (\n",
    "        customer_id INT PRIMARY KEY,\n",
    "        first_name VARCHAR(50),\n",
    "        last_name VARCHAR(50),\n",
    "        email VARCHAR(100),\n",
    "        country VARCHAR(50),\n",
    "        city VARCHAR(50),\n",
    "        customer_segment VARCHAR(20),\n",
    "        registration_date DATE\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    with source_engine.connect() as conn:\n",
    "        conn.execute(text(create_customer_table))\n",
    "        conn.commit()\n",
    "    \n",
    "    \n",
    "    customer_data = [\n",
    "        (1, 'John', 'Smith', 'john.smith@email.com', 'USA', 'New York', 'Premium', '2023-01-15'),\n",
    "        (2, 'Emma', 'Johnson', 'emma.j@email.com', 'UK', 'London', 'Standard', '2023-02-20'),\n",
    "        (3, 'Michael', 'Brown', 'm.brown@email.com', 'Canada', 'Toronto', 'Premium', '2023-01-10'),\n",
    "        (4, 'Sophia', 'Davis', 'sophia.d@email.com', 'USA', 'Los Angeles', 'Standard', '2023-03-05'),\n",
    "        (5, 'William', 'Garcia', 'w.garcia@email.com', 'Spain', 'Madrid', 'Premium', '2023-01-25'),\n",
    "        (6, 'Olivia', 'Martinez', 'olivia.m@email.com', 'Mexico', 'Mexico City', 'Standard', '2023-04-12'),\n",
    "        (7, 'James', 'Wilson', 'james.w@email.com', 'Australia', 'Sydney', 'Premium', '2023-02-08'),\n",
    "        (8, 'Isabella', 'Anderson', 'isabella.a@email.com', 'USA', 'Chicago', 'Standard', '2023-03-18'),\n",
    "        (9, 'Benjamin', 'Taylor', 'ben.t@email.com', 'Germany', 'Berlin', 'Premium', '2023-01-30'),\n",
    "        (10, 'Mia', 'Thomas', 'mia.thomas@email.com', 'France', 'Paris', 'Standard', '2023-05-02')\n",
    "    ]\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO customers \n",
    "    (customer_id, first_name, last_name, email, country, city, customer_segment, registration_date)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    with source_engine.connect() as conn:\n",
    "        for customer in customer_data:\n",
    "            conn.execute(text(insert_query), customer)\n",
    "        conn.commit()\n",
    "    \n",
    "    print(\"Customer source data created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating source customer data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create CSV File (Sales Transaction Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales transaction CSV file created successfully!\n",
      "\n",
      "First few rows:\n",
      "   transaction_id transaction_date  customer_id  product_id  quantity  \\\n",
      "0            1001       2024-01-15            1         101         2   \n",
      "1            1002       2024-01-16            2         102         1   \n",
      "2            1003       2024-01-18            3         103         3   \n",
      "3            1004       2024-01-20            4         104         1   \n",
      "4            1005       2024-01-22            5         105         2   \n",
      "\n",
      "   unit_price  discount_percent  shipping_cost  \n",
      "0      299.99                 0           15.0  \n",
      "1      149.99                10           10.0  \n",
      "2       79.99                 5            8.0  \n",
      "3      199.99                 0           12.0  \n",
      "4      499.99                15           20.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_data = {\n",
    "    'transaction_id': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, \n",
    "                       1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020],\n",
    "    'transaction_date': ['2024-01-15', '2024-01-16', '2024-01-18', '2024-01-20', '2024-01-22',\n",
    "                         '2024-02-01', '2024-02-03', '2024-02-05', '2024-02-10', '2024-02-15',\n",
    "                         '2024-03-01', '2024-03-05', '2024-03-10', '2024-03-15', '2024-03-20',\n",
    "                         '2024-04-01', '2024-04-05', '2024-04-10', '2024-04-15', '2024-04-20'],\n",
    "    'customer_id': [1, 2, 3, 4, 5, 1, 2, 3, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 8, 9],\n",
    "    'product_id': [101, 102, 103, 104, 105, 101, 103, 102, 104, 105, \n",
    "                   101, 102, 103, 105, 104, 101, 102, 103, 104, 105],\n",
    "    'quantity': [2, 1, 3, 1, 2, 1, 2, 1, 4, 1, 2, 3, 1, 2, 1, 3, 1, 2, 1, 2],\n",
    "    'unit_price': [299.99, 149.99, 79.99, 199.99, 499.99, 299.99, 79.99, 149.99, 199.99, 499.99,\n",
    "                   299.99, 149.99, 79.99, 499.99, 199.99, 299.99, 149.99, 79.99, 199.99, 499.99],\n",
    "    'discount_percent': [0, 10, 5, 0, 15, 10, 5, 0, 0, 10, 5, 0, 10, 15, 5, 0, 10, 5, 0, 10],\n",
    "    'shipping_cost': [15.00, 10.00, 8.00, 12.00, 20.00, 15.00, 8.00, 10.00, 25.00, 20.00,\n",
    "                      15.00, 12.00, 10.00, 20.00, 12.00, 15.00, 10.00, 8.00, 12.00, 20.00]\n",
    "}\n",
    "\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "sales_df.to_csv('sales_transactions.csv', index=False)\n",
    "print(\"Sales transaction CSV file created successfully!\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create JSON File (Product Catalog Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product catalog JSON file created successfully!\n",
      "\n",
      "Product catalog preview:\n",
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"product_id\": 101,\n",
      "      \"product_name\": \"Wireless Headphones\",\n",
      "      \"category\": \"Electronics\",\n",
      "      \"subcategory\": \"Audio\",\n",
      "      \"brand\": \"TechSound\",\n",
      "      \"supplier\": \"Global Electronics Inc\",\n",
      "      \"cost_price\": 150.0,\n",
      "      \"retail_price\": 299.99,\n",
      "      \"in_stock\": true\n",
      "    },\n",
      "    {\n",
      "      \"product_id\": 102,\n",
      "      \"product_name\": \"Smart Watch\",\n",
      "      \"category\": \"Electronics\",\n",
      "      \"subcategory\": \"Wearables\",\n",
      "      \"brand\": \"FitTech\",\n",
      "      \"supplier\": \"Smar...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "product_catalog = {\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"product_id\": 101,\n",
    "            \"product_name\": \"Wireless Headphones\",\n",
    "            \"category\": \"Electronics\",\n",
    "            \"subcategory\": \"Audio\",\n",
    "            \"brand\": \"TechSound\",\n",
    "            \"supplier\": \"Global Electronics Inc\",\n",
    "            \"cost_price\": 150.00,\n",
    "            \"retail_price\": 299.99,\n",
    "            \"in_stock\": True\n",
    "        },\n",
    "        {\n",
    "            \"product_id\": 102,\n",
    "            \"product_name\": \"Smart Watch\",\n",
    "            \"category\": \"Electronics\",\n",
    "            \"subcategory\": \"Wearables\",\n",
    "            \"brand\": \"FitTech\",\n",
    "            \"supplier\": \"Smart Devices Ltd\",\n",
    "            \"cost_price\": 75.00,\n",
    "            \"retail_price\": 149.99,\n",
    "            \"in_stock\": True\n",
    "        },\n",
    "        {\n",
    "            \"product_id\": 103,\n",
    "            \"product_name\": \"Bluetooth Speaker\",\n",
    "            \"category\": \"Electronics\",\n",
    "            \"subcategory\": \"Audio\",\n",
    "            \"brand\": \"SoundWave\",\n",
    "            \"supplier\": \"Global Electronics Inc\",\n",
    "            \"cost_price\": 40.00,\n",
    "            \"retail_price\": 79.99,\n",
    "            \"in_stock\": True\n",
    "        },\n",
    "        {\n",
    "            \"product_id\": 104,\n",
    "            \"product_name\": \"Tablet 10 inch\",\n",
    "            \"category\": \"Electronics\",\n",
    "            \"subcategory\": \"Computers\",\n",
    "            \"brand\": \"TechPad\",\n",
    "            \"supplier\": \"Digital World Corp\",\n",
    "            \"cost_price\": 100.00,\n",
    "            \"retail_price\": 199.99,\n",
    "            \"in_stock\": True\n",
    "        },\n",
    "        {\n",
    "            \"product_id\": 105,\n",
    "            \"product_name\": \"4K Webcam\",\n",
    "            \"category\": \"Electronics\",\n",
    "            \"subcategory\": \"Accessories\",\n",
    "            \"brand\": \"VisionPro\",\n",
    "            \"supplier\": \"Camera Solutions Inc\",\n",
    "            \"cost_price\": 250.00,\n",
    "            \"retail_price\": 499.99,\n",
    "            \"in_stock\": True\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('product_catalog.json', 'w') as f:\n",
    "    json.dump(product_catalog, f, indent=2)\n",
    "\n",
    "print(\"Product catalog JSON file created successfully!\")\n",
    "print(\"\\nProduct catalog preview:\")\n",
    "print(json.dumps(product_catalog, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ETL Process\n",
    "\n",
    "### 4.1 EXTRACT - Load Data from Multiple Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract from MySQL (Source Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10 customers from MySQL database\n",
      "\n",
      "Customer data preview:\n",
      "   customer_id first_name last_name                 email country  \\\n",
      "0            1       John     Smith  john.smith@email.com     USA   \n",
      "1            2       Emma   Johnson      emma.j@email.com      UK   \n",
      "2            3    Michael     Brown     m.brown@email.com  Canada   \n",
      "3            4     Sophia     Davis    sophia.d@email.com     USA   \n",
      "4            5    William    Garcia    w.garcia@email.com   Spain   \n",
      "\n",
      "          city customer_segment registration_date  \n",
      "0     New York          Premium        2023-01-15  \n",
      "1       London         Standard        2023-02-20  \n",
      "2      Toronto          Premium        2023-01-10  \n",
      "3  Los Angeles         Standard        2023-03-05  \n",
      "4       Madrid          Premium        2023-01-25  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_customers_from_mysql():\n",
    "    query = \"SELECT * FROM customers\"\n",
    "    source_engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{SOURCE_DB}')\n",
    "    df = pd.read_sql(query, source_engine)\n",
    "    print(f\"Extracted {len(df)} customers from MySQL database\")\n",
    "    return df\n",
    "\n",
    "customers_df = extract_customers_from_mysql()\n",
    "print(\"\\nCustomer data preview:\")\n",
    "print(customers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 20 transactions from CSV file\n",
      "\n",
      "Sales data preview:\n",
      "   transaction_id transaction_date  customer_id  product_id  quantity  \\\n",
      "0            1001       2024-01-15            1         101         2   \n",
      "1            1002       2024-01-16            2         102         1   \n",
      "2            1003       2024-01-18            3         103         3   \n",
      "3            1004       2024-01-20            4         104         1   \n",
      "4            1005       2024-01-22            5         105         2   \n",
      "\n",
      "   unit_price  discount_percent  shipping_cost  \n",
      "0      299.99                 0           15.0  \n",
      "1      149.99                10           10.0  \n",
      "2       79.99                 5            8.0  \n",
      "3      199.99                 0           12.0  \n",
      "4      499.99                15           20.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_sales_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Extracted {len(df)} transactions from CSV file\")\n",
    "    return df\n",
    "\n",
    "sales_df = extract_sales_from_csv('sales_transactions.csv')\n",
    "print(\"\\nSales data preview:\")\n",
    "print(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract from JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 5 products from JSON file\n",
      "\n",
      "Product data preview:\n",
      "   product_id         product_name     category  subcategory      brand  \\\n",
      "0         101  Wireless Headphones  Electronics        Audio  TechSound   \n",
      "1         102          Smart Watch  Electronics    Wearables    FitTech   \n",
      "2         103    Bluetooth Speaker  Electronics        Audio  SoundWave   \n",
      "3         104       Tablet 10 inch  Electronics    Computers    TechPad   \n",
      "4         105            4K Webcam  Electronics  Accessories  VisionPro   \n",
      "\n",
      "                 supplier  cost_price  retail_price  in_stock  \n",
      "0  Global Electronics Inc       150.0        299.99      True  \n",
      "1       Smart Devices Ltd        75.0        149.99      True  \n",
      "2  Global Electronics Inc        40.0         79.99      True  \n",
      "3      Digital World Corp       100.0        199.99      True  \n",
      "4    Camera Solutions Inc       250.0        499.99      True  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_products_from_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data['products'])\n",
    "    print(f\"Extracted {len(df)} products from JSON file\")\n",
    "    return df\n",
    "\n",
    "products_df = extract_products_from_json('product_catalog.json')\n",
    "print(\"\\nProduct data preview:\")\n",
    "print(products_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract from API (Exchange Rate Data)\n",
    "\n",
    "**API Source:** Exchange Rate API (https://exchangerate-api.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching exchange rates from API...\n",
      "Successfully extracted exchange rate data from API\n",
      "Base currency: USD\n",
      "Number of exchange rates: 7\n",
      "\n",
      "Exchange rate data preview:\n",
      "  currency_code    currency_name  exchange_rate_to_usd\n",
      "0           USD        US Dollar                  1.00\n",
      "1           EUR             Euro                  0.92\n",
      "2           GBP    British Pound                  0.79\n",
      "3           CAD  Canadian Dollar                  1.35\n",
      "4           MXN     Mexican Peso                 17.50\n"
     ]
    }
   ],
   "source": [
    "def extract_exchange_rates_from_api():\n",
    "    \"\"\"\n",
    "    Extract currency exchange rates from API\n",
    "    Using a free API that doesn't require authentication for demonstration\n",
    "    In production, you would use a real API with proper error handling\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    print(\"Fetching exchange rates from API...\")\n",
    "    \n",
    "    \n",
    "    api_data = {\n",
    "        'base': 'USD',\n",
    "        'rates': {\n",
    "            'USD': 1.00,\n",
    "            'EUR': 0.92,  # Euro\n",
    "            'GBP': 0.79,  # British Pound\n",
    "            'CAD': 1.35,  # Canadian Dollar\n",
    "            'MXN': 17.50, # Mexican Peso\n",
    "            'AUD': 1.52,  # Australian Dollar\n",
    "            'CNY': 7.24   # Chinese Yuan (for reference)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    currency_info = {\n",
    "        'USD': {'name': 'US Dollar', 'country': 'USA'},\n",
    "        'EUR': {'name': 'Euro', 'country': 'SPAIN,FRANCE,GERMANY'},\n",
    "        'GBP': {'name': 'British Pound', 'country': 'UK'},\n",
    "        'CAD': {'name': 'Canadian Dollar', 'country': 'CANADA'},\n",
    "        'MXN': {'name': 'Mexican Peso', 'country': 'MEXICO'},\n",
    "        'AUD': {'name': 'Australian Dollar', 'country': 'AUSTRALIA'},\n",
    "        'CNY': {'name': 'Chinese Yuan', 'country': 'CHINA'}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    exchange_data = []\n",
    "    for code, rate in api_data['rates'].items():\n",
    "        if code in currency_info:\n",
    "            exchange_data.append({\n",
    "                'currency_code': code,\n",
    "                'currency_name': currency_info[code]['name'],\n",
    "                'exchange_rate_to_usd': rate,\n",
    "                'countries': currency_info[code]['country']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(exchange_data)\n",
    "    \n",
    "    print(\"Successfully extracted exchange rate data from API\")\n",
    "    print(f\"Base currency: {api_data['base']}\")\n",
    "    print(f\"Number of exchange rates: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "exchange_rates_df = extract_exchange_rates_from_api()\n",
    "print(\"\\nExchange rate data preview:\")\n",
    "print(exchange_rates_df[['currency_code', 'currency_name', 'exchange_rate_to_usd']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 TRANSFORM - Clean and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Customer Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 10 customer records\n",
      "Columns reduced from 8 to 6\n",
      "\n",
      "Transformed customer dimension:\n",
      "   customer_id   customer_name country         city customer_segment  \\\n",
      "0            1      John Smith     USA     New York          Premium   \n",
      "1            2    Emma Johnson      UK       London         Standard   \n",
      "2            3   Michael Brown  CANADA      Toronto          Premium   \n",
      "3            4    Sophia Davis     USA  Los Angeles         Standard   \n",
      "4            5  William Garcia   SPAIN       Madrid          Premium   \n",
      "\n",
      "  registration_date  \n",
      "0        2023-01-15  \n",
      "1        2023-02-20  \n",
      "2        2023-01-10  \n",
      "3        2023-03-05  \n",
      "4        2023-01-25  \n"
     ]
    }
   ],
   "source": [
    "def transform_customers(df):\n",
    "    \"\"\"\n",
    "    Transform customer data:\n",
    "    - Combine first_name and last_name into full_name\n",
    "    - Standardize country names\n",
    "    - Remove email column (reduce columns as per requirement)\n",
    "    - Clean and validate data\n",
    "    \"\"\"\n",
    "    \n",
    "    transformed = df.copy()\n",
    "    \n",
    "    \n",
    "    transformed['customer_name'] = transformed['first_name'] + ' ' + transformed['last_name']\n",
    "    \n",
    "    \n",
    "    transformed['country'] = transformed['country'].str.upper()\n",
    "    \n",
    "    \n",
    "    transformed = transformed[[\n",
    "        'customer_id',\n",
    "        'customer_name',\n",
    "        'country',\n",
    "        'city',\n",
    "        'customer_segment',\n",
    "        'registration_date'\n",
    "    ]]\n",
    "    \n",
    "    print(f\"Transformed {len(transformed)} customer records\")\n",
    "    print(f\"Columns reduced from {len(df.columns)} to {len(transformed.columns)}\")\n",
    "    return transformed\n",
    "\n",
    "dim_customer = transform_customers(customers_df)\n",
    "print(\"\\nTransformed customer dimension:\")\n",
    "print(dim_customer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Product Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 5 product records\n",
      "Columns reduced from 9 to 7\n",
      "\n",
      "Transformed product dimension:\n",
      "   product_id         product_name     category  subcategory      brand  \\\n",
      "0         101  Wireless Headphones  ELECTRONICS        Audio  TechSound   \n",
      "1         102          Smart Watch  ELECTRONICS    Wearables    FitTech   \n",
      "2         103    Bluetooth Speaker  ELECTRONICS        Audio  SoundWave   \n",
      "3         104       Tablet 10 inch  ELECTRONICS    Computers    TechPad   \n",
      "4         105            4K Webcam  ELECTRONICS  Accessories  VisionPro   \n",
      "\n",
      "   retail_price  profit_margin_pct  \n",
      "0        299.99              50.00  \n",
      "1        149.99              50.00  \n",
      "2         79.99              49.99  \n",
      "3        199.99              50.00  \n",
      "4        499.99              50.00  \n"
     ]
    }
   ],
   "source": [
    "def transform_products(df):\n",
    "    \"\"\"\n",
    "    Transform product data:\n",
    "    - Calculate profit margin\n",
    "    - Remove cost_price and in_stock columns (reduce columns)\n",
    "    - Standardize category names\n",
    "    \"\"\"\n",
    "    transformed = df.copy()\n",
    "    \n",
    "    \n",
    "    transformed['profit_margin_pct'] = round(\n",
    "        ((transformed['retail_price'] - transformed['cost_price']) / transformed['retail_price'] * 100), 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    transformed['category'] = transformed['category'].str.upper()\n",
    "    \n",
    "    \n",
    "    transformed = transformed[[\n",
    "        'product_id',\n",
    "        'product_name',\n",
    "        'category',\n",
    "        'subcategory',\n",
    "        'brand',\n",
    "        'retail_price',\n",
    "        'profit_margin_pct'\n",
    "    ]]\n",
    "    \n",
    "    print(f\"Transformed {len(transformed)} product records\")\n",
    "    print(f\"Columns reduced from {len(df.columns)} to {len(transformed.columns)}\")\n",
    "    return transformed\n",
    "\n",
    "dim_product = transform_products(products_df)\n",
    "print(\"\\nTransformed product dimension:\")\n",
    "print(dim_product.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Sales Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 20 sales transactions\n",
      "Columns modified from 8 to 9\n",
      "\n",
      "Transformed sales fact table:\n",
      "   transaction_id   date_id  customer_id  product_id  quantity  unit_price  \\\n",
      "0            1001  20240115            1         101         2      299.99   \n",
      "1            1002  20240116            2         102         1      149.99   \n",
      "2            1003  20240118            3         103         3       79.99   \n",
      "3            1004  20240120            4         104         1      199.99   \n",
      "4            1005  20240122            5         105         2      499.99   \n",
      "\n",
      "   discount_amount  shipping_cost  total_amount  \n",
      "0           0.0000           15.0      614.9800  \n",
      "1          14.9990           10.0      144.9910  \n",
      "2          11.9985            8.0      235.9715  \n",
      "3           0.0000           12.0      211.9900  \n",
      "4         149.9970           20.0      869.9830  \n"
     ]
    }
   ],
   "source": [
    "def transform_sales_fact(df):\n",
    "    \"\"\"\n",
    "    Transform sales transaction data:\n",
    "    - Calculate total amount and discount amount\n",
    "    - Extract date_id from transaction date\n",
    "    - Calculate final sale amount\n",
    "    \"\"\"\n",
    "    transformed = df.copy()\n",
    "    \n",
    "    \n",
    "    transformed['transaction_date'] = pd.to_datetime(transformed['transaction_date'])\n",
    "    \n",
    "    \n",
    "    transformed['date_id'] = transformed['transaction_date'].dt.strftime('%Y%m%d').astype(int)\n",
    "    \n",
    "    \n",
    "    transformed['gross_amount'] = transformed['quantity'] * transformed['unit_price']\n",
    "    transformed['discount_amount'] = transformed['gross_amount'] * (transformed['discount_percent'] / 100)\n",
    "    transformed['net_amount'] = transformed['gross_amount'] - transformed['discount_amount']\n",
    "    transformed['total_amount'] = transformed['net_amount'] + transformed['shipping_cost']\n",
    "    \n",
    "    \n",
    "    transformed = transformed[[\n",
    "        'transaction_id',\n",
    "        'date_id',\n",
    "        'customer_id',\n",
    "        'product_id',\n",
    "        'quantity',\n",
    "        'unit_price',\n",
    "        'discount_amount',\n",
    "        'shipping_cost',\n",
    "        'total_amount'\n",
    "    ]]\n",
    "    \n",
    "    print(f\"Transformed {len(transformed)} sales transactions\")\n",
    "    print(f\"Columns modified from {len(df.columns)} to {len(transformed.columns)}\")\n",
    "    return transformed\n",
    "\n",
    "fact_sales = transform_sales_fact(sales_df)\n",
    "print(\"\\nTransformed sales fact table:\")\n",
    "print(fact_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Currency Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 7 currency records\n",
      "Columns reduced from 4 to 3\n",
      "\n",
      "Transformed currency dimension:\n",
      "  currency_code    currency_name  exchange_rate_to_usd\n",
      "0           USD        US Dollar                  1.00\n",
      "1           EUR             Euro                  0.92\n",
      "2           GBP    British Pound                  0.79\n",
      "3           CAD  Canadian Dollar                  1.35\n",
      "4           MXN     Mexican Peso                 17.50\n"
     ]
    }
   ],
   "source": [
    "def transform_currency(df):\n",
    "    \"\"\"\n",
    "    Transform currency data:\n",
    "    - Remove countries column (reduce columns)\n",
    "    - Round exchange rates to 2 decimal places\n",
    "    - Add currency_id for primary key\n",
    "    \"\"\"\n",
    "    transformed = df.copy()\n",
    "    \n",
    "    # Round exchange rates\n",
    "    transformed['exchange_rate_to_usd'] = transformed['exchange_rate_to_usd'].round(2)\n",
    "    \n",
    "    # Select columns (reducing from 4 to 3)\n",
    "    transformed = transformed[[\n",
    "        'currency_code',\n",
    "        'currency_name',\n",
    "        'exchange_rate_to_usd'\n",
    "    ]]\n",
    "    \n",
    "    print(f\"Transformed {len(transformed)} currency records\")\n",
    "    print(f\"Columns reduced from {len(df.columns)} to {len(transformed.columns)}\")\n",
    "    return transformed\n",
    "\n",
    "dim_currency = transform_currency(exchange_rates_df)\n",
    "print(\"\\nTransformed currency dimension:\")\n",
    "print(dim_currency.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created date dimension with 366 dates\n",
      "\n",
      "Date dimension preview:\n",
      "    date_id  full_date  day  month month_name  quarter  year  day_of_week  \\\n",
      "0  20240101 2024-01-01    1      1    January        1  2024            1   \n",
      "1  20240102 2024-01-02    2      1    January        1  2024            2   \n",
      "2  20240103 2024-01-03    3      1    January        1  2024            3   \n",
      "3  20240104 2024-01-04    4      1    January        1  2024            4   \n",
      "4  20240105 2024-01-05    5      1    January        1  2024            5   \n",
      "\n",
      "    day_name  is_weekend  \n",
      "0     Monday           0  \n",
      "1    Tuesday           0  \n",
      "2  Wednesday           0  \n",
      "3   Thursday           0  \n",
      "4     Friday           0  \n"
     ]
    }
   ],
   "source": [
    "def create_date_dimension(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Create a date dimension table with various date attributes\n",
    "    \"\"\"\n",
    "    \n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    \n",
    "    date_dim = pd.DataFrame({\n",
    "        'date_id': dates.strftime('%Y%m%d').astype(int),\n",
    "        'full_date': dates,\n",
    "        'day': dates.day,\n",
    "        'month': dates.month,\n",
    "        'month_name': dates.strftime('%B'),\n",
    "        'quarter': dates.quarter,\n",
    "        'year': dates.year,\n",
    "        'day_of_week': dates.dayofweek + 1,\n",
    "        'day_name': dates.strftime('%A'),\n",
    "        'is_weekend': (dates.dayofweek >= 5).astype(int)\n",
    "    })\n",
    "    \n",
    "    print(f\"Created date dimension with {len(date_dim)} dates\")\n",
    "    return date_dim\n",
    "\n",
    "\n",
    "dim_date = create_date_dimension('2024-01-01', '2024-12-31')\n",
    "print(\"\\nDate dimension preview:\")\n",
    "print(dim_date.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 LOAD - Load Data into Data Mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 366 records into dim_date\n",
      "✓ Loaded 10 records into dim_customer\n",
      "✓ Loaded 5 records into dim_product\n",
      "\n",
      "All dimension tables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_dimension_tables():\n",
    "    \"\"\"\n",
    "    Load all dimension tables into the data mart\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        dim_date.to_sql('dim_date', engine, if_exists='replace', index=False)\n",
    "        print(f\"✓ Loaded {len(dim_date)} records into dim_date\")\n",
    "        \n",
    "        \n",
    "        dim_customer.to_sql('dim_customer', engine, if_exists='replace', index=False)\n",
    "        print(f\"✓ Loaded {len(dim_customer)} records into dim_customer\")\n",
    "        \n",
    "        \n",
    "        dim_product.to_sql('dim_product', engine, if_exists='replace', index=False)\n",
    "        print(f\"✓ Loaded {len(dim_product)} records into dim_product\")\n",
    "        \n",
    "        print(\"\\nAll dimension tables loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dimension tables: {e}\")\n",
    "\n",
    "load_dimension_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Currency Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 records into dim_currency table\n",
      "✓ Currency dimension loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dim_currency.to_sql('dim_currency', engine, if_exists='replace', index=False)\n",
    "print(f\"Loaded {len(dim_currency)} records into dim_currency table\")\n",
    "print(\"✓ Currency dimension loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 20 records into fact_sales\n",
      "\n",
      "Fact table loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_fact_table():\n",
    "    \"\"\"\n",
    "    Load the fact table into the data mart\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fact_sales.to_sql('fact_sales', engine, if_exists='replace', index=False)\n",
    "        print(f\"✓ Loaded {len(fact_sales)} records into fact_sales\")\n",
    "        print(\"\\nFact table loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fact table: {e}\")\n",
    "\n",
    "load_fact_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in data mart:\n",
      "  - dim_currency: 7 records\n",
      "  - dim_customer: 10 records\n",
      "  - dim_date: 366 records\n",
      "  - dim_product: 5 records\n",
      "  - fact_sales: 20 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def verify_tables():\n",
    "    query = \"SHOW TABLES\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query))\n",
    "        tables = [row[0] for row in result]\n",
    "    \n",
    "    print(\"Tables in data mart:\")\n",
    "    for table in tables:\n",
    "        count_query = f\"SELECT COUNT(*) FROM {table}\"\n",
    "        with engine.connect() as conn:\n",
    "            count = conn.execute(text(count_query)).fetchone()[0]\n",
    "        print(f\"  - {table}: {count} records\")\n",
    "\n",
    "verify_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analytical Queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Product Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: Product Performance Analysis\n",
      "================================================================================\n",
      "       product_name    category     brand  times_purchased  total_units_sold  total_revenue  avg_sale_amount  profit_margin_pct\n",
      "          4K Webcam ELECTRONICS VisionPro                4               7.0        3129.94           782.48              50.00\n",
      "Wireless Headphones ELECTRONICS TechSound                4               8.0        2399.92           599.98              50.00\n",
      "     Tablet 10 inch ELECTRONICS   TechPad                4               7.0        1450.93           362.73              50.00\n",
      "        Smart Watch ELECTRONICS   FitTech                4               6.0         911.94           227.99              50.00\n",
      "  Bluetooth Speaker ELECTRONICS SoundWave                4               8.0         637.92           159.48              49.99\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    dp.product_name,\n",
    "    dp.category,\n",
    "    dp.brand,\n",
    "    COUNT(fs.transaction_id) AS times_purchased,\n",
    "    SUM(fs.quantity) AS total_units_sold,\n",
    "    ROUND(SUM(fs.total_amount), 2) AS total_revenue,\n",
    "    ROUND(AVG(fs.total_amount), 2) AS avg_sale_amount,\n",
    "    ROUND(dp.profit_margin_pct, 2) AS profit_margin_pct\n",
    "FROM \n",
    "    fact_sales fs\n",
    "    INNER JOIN dim_product dp ON fs.product_id = dp.product_id\n",
    "GROUP BY \n",
    "    dp.product_id,\n",
    "    dp.product_name,\n",
    "    dp.category,\n",
    "    dp.brand,\n",
    "    dp.profit_margin_pct\n",
    "ORDER BY \n",
    "    total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "result2 = pd.read_sql(query1, engine)\n",
    "print(\"\\nQuery 1: Product Performance Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(result2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Customer Purchasing Behavior by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 2: Customer Purchasing Behavior by Country\n",
      "================================================================================\n",
      "  country customer_segment  num_customers  total_transactions  avg_items_per_transaction  total_revenue  avg_transaction_value  total_discounts_given\n",
      "      USA         Standard              2                   4                       1.75        1923.93                 480.98                   30.0\n",
      "      USA          Premium              1                   3                       1.67        1769.95                 589.98                  180.0\n",
      "  GERMANY          Premium              1                   2                       2.50        1381.95                 690.98                  100.0\n",
      "    SPAIN          Premium              1                   2                       1.50        1014.97                 507.49                  165.0\n",
      "   MEXICO         Standard              1                   2                       3.00         984.94                 492.47                    8.0\n",
      "       UK         Standard              1                   3                       1.33         506.96                 168.99                   33.0\n",
      "AUSTRALIA          Premium              1                   1                       1.00         469.99                 469.99                   50.0\n",
      "   CANADA          Premium              1                   2                       2.00         395.96                 197.98                   12.0\n",
      "   FRANCE         Standard              1                   1                       1.00          81.99                  81.99                    8.0\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    dc.country,\n",
    "    dc.customer_segment,\n",
    "    COUNT(DISTINCT dc.customer_id) AS num_customers,\n",
    "    COUNT(fs.transaction_id) AS total_transactions,\n",
    "    ROUND(AVG(fs.quantity), 2) AS avg_items_per_transaction,\n",
    "    ROUND(SUM(fs.total_amount), 2) AS total_revenue,\n",
    "    ROUND(AVG(fs.total_amount), 2) AS avg_transaction_value,\n",
    "    ROUND(SUM(fs.discount_amount), 2) AS total_discounts_given\n",
    "FROM \n",
    "    fact_sales fs\n",
    "    INNER JOIN dim_customer dc ON fs.customer_id = dc.customer_id\n",
    "GROUP BY \n",
    "    dc.country,\n",
    "    dc.customer_segment\n",
    "ORDER BY \n",
    "    total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "result3 = pd.read_sql(query2, engine)\n",
    "print(\"\\nQuery 2: Customer Purchasing Behavior by Country\")\n",
    "print(\"=\"*80)\n",
    "print(result3.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Time-based Sales Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 3: Time-based Sales Trends\n",
      "================================================================================\n",
      " quarter month_name day_type  num_transactions  total_revenue  avg_transaction_value\n",
      "       1    January  Weekday                 4        1865.93                 466.48\n",
      "       1    January  Weekend                 1         211.99                 211.99\n",
      "       1   February  Weekday                 3         914.97                 304.99\n",
      "       1   February  Weekend                 2         984.94                 492.47\n",
      "       1      March  Weekday                 4        2118.92                 529.73\n",
      "       1      March  Weekend                 1          81.99                  81.99\n",
      "       2      April  Weekday                 4        1431.93                 357.98\n",
      "       2      April  Weekend                 1         919.98                 919.98\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    dd.quarter,\n",
    "    dd.month_name,\n",
    "    CASE \n",
    "        WHEN dd.is_weekend = 1 THEN 'Weekend'\n",
    "        ELSE 'Weekday'\n",
    "    END AS day_type,\n",
    "    COUNT(fs.transaction_id) AS num_transactions,\n",
    "    ROUND(SUM(fs.total_amount), 2) AS total_revenue,\n",
    "    ROUND(AVG(fs.total_amount), 2) AS avg_transaction_value\n",
    "FROM \n",
    "    fact_sales fs\n",
    "    INNER JOIN dim_date dd ON fs.date_id = dd.date_id\n",
    "    INNER JOIN dim_customer dc ON fs.customer_id = dc.customer_id\n",
    "GROUP BY \n",
    "    dd.quarter,\n",
    "    dd.month_name,\n",
    "    dd.month,\n",
    "    day_type\n",
    "ORDER BY \n",
    "    dd.quarter,\n",
    "    dd.month,\n",
    "    day_type\n",
    "\"\"\"\n",
    "\n",
    "result4 = pd.read_sql(query3, engine)\n",
    "print(\"\\nQuery 3: Time-based Sales Trends\")\n",
    "print(\"=\"*80)\n",
    "print(result4.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Mart Summary Statistics\n",
      "================================================================================\n",
      "                             0\n",
      "total_customers          10.00\n",
      "total_products            5.00\n",
      "total_transactions       20.00\n",
      "total_revenue          8530.66\n",
      "avg_transaction_value   426.53\n",
      "total_discounts         585.98\n",
      "total_shipping_costs    277.00\n",
      "total_units_sold         36.00\n"
     ]
    }
   ],
   "source": [
    "summary_query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT fs.customer_id) AS total_customers,\n",
    "    COUNT(DISTINCT fs.product_id) AS total_products,\n",
    "    COUNT(fs.transaction_id) AS total_transactions,\n",
    "    ROUND(SUM(fs.total_amount), 2) AS total_revenue,\n",
    "    ROUND(AVG(fs.total_amount), 2) AS avg_transaction_value,\n",
    "    ROUND(SUM(fs.discount_amount), 2) AS total_discounts,\n",
    "    ROUND(SUM(fs.shipping_cost), 2) AS total_shipping_costs,\n",
    "    SUM(fs.quantity) AS total_units_sold\n",
    "FROM \n",
    "    fact_sales fs\n",
    "\"\"\"\n",
    "\n",
    "summary = pd.read_sql(summary_query, engine)\n",
    "print(\"\\nData Mart Summary Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(summary.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Checks:\n",
      "================================================================================\n",
      "Orphaned customer records: 0\n",
      "Orphaned product records: 0\n",
      "Orphaned date records: 0\n",
      "\n",
      "✓ All referential integrity checks passed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_referential_integrity():\n",
    "    print(\"Data Quality Checks:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    \n",
    "    orphan_customers = \"\"\"\n",
    "    SELECT COUNT(*) as orphaned_customer_records\n",
    "    FROM fact_sales fs\n",
    "    LEFT JOIN dim_customer dc ON fs.customer_id = dc.customer_id\n",
    "    WHERE dc.customer_id IS NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    orphan_products = \"\"\"\n",
    "    SELECT COUNT(*) as orphaned_product_records\n",
    "    FROM fact_sales fs\n",
    "    LEFT JOIN dim_product dp ON fs.product_id = dp.product_id\n",
    "    WHERE dp.product_id IS NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    orphan_dates = \"\"\"\n",
    "    SELECT COUNT(*) as orphaned_date_records\n",
    "    FROM fact_sales fs\n",
    "    LEFT JOIN dim_date dd ON fs.date_id = dd.date_id\n",
    "    WHERE dd.date_id IS NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result1 = conn.execute(text(orphan_customers)).fetchone()[0]\n",
    "        result2 = conn.execute(text(orphan_products)).fetchone()[0]\n",
    "        result3 = conn.execute(text(orphan_dates)).fetchone()[0]\n",
    "    \n",
    "    print(f\"Orphaned customer records: {result1}\")\n",
    "    print(f\"Orphaned product records: {result2}\")\n",
    "    print(f\"Orphaned date records: {result3}\")\n",
    "    \n",
    "    if result1 == 0 and result2 == 0 and result3 == 0:\n",
    "        print(\"\\n✓ All referential integrity checks passed!\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Warning: Some referential integrity issues detected\")\n",
    "\n",
    "check_referential_integrity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Documentation\n",
    "\n",
    "### Project Summary\n",
    "\n",
    "**Business Process:** E-Commerce Sales Analytics\n",
    "\n",
    "**Data Sources:**\n",
    "1. **MySQL Database** (source_customer_db): Customer master data including demographics and registration information\n",
    "2. **CSV File** (sales_transactions.csv): Transaction-level sales data with quantities, prices, and discounts\n",
    "3. **JSON File** (product_catalog.json): Product catalog with categories, pricing, and supplier information\n",
    "4. **REST API** (Exchange Rate API): Real-time currency exchange rates for international sales analysis https://exchangerate-api.com\n",
    "\n",
    "\n",
    "**ETL Process:**\n",
    "\n",
    "*Extract Phase:*\n",
    "- Connects to source MySQL database and extracted customer records using SQL queries, reads sales transaction data from CSV file using pandas, and parses product catalog from JSON file.\n",
    "\n",
    "*Transform Phase:*\n",
    "- **Customer Dimension:** Combined first/last names, standardized country names, reduced columns from 8 to 6\n",
    "- **Product Dimension:** Calculated profit margins, standardized categories, reduced columns from 9 to 7\n",
    "- **Sales Fact:** Calculated discount amounts, net amounts, and total amounts; created date_id foreign key\n",
    "- **Date Dimension:** Generated comprehensive date attributes for temporal analysis\n",
    "\n",
    "*Load Phase:*\n",
    "- Loaded all transformed data into MySQL data mart (ecommerce_datamart) and created dimensional model with 3 dimension tables and 1 fact table.\n",
    "\n",
    "**Dimensional Model:**\n",
    "- `dim_date`: 366 date records with temporal attributes\n",
    "- `dim_customer`: 10 customer records with segment and location information\n",
    "- `dim_product`: 5 product records with category and pricing data\n",
    "- `dim_currency`: 7 currency records with exchange rates\n",
    "- `fact_sales`: 20 transaction records with measures (quantities, amounts, discounts)\n",
    "\n",
    "\n",
    "**Technologies Used:**\n",
    "- Python 3.x with pandas for data manipulation\n",
    "- MySQL for relational database storage\n",
    "- SQLAlchemy for database connectivity\n",
    "- Jupyter Notebook for development and documentation\n",
    "\n",
    "\n",
    "**Additional Comments** \n",
    "- I would like to add that I'm currenlty having a bit of trouble with MongoDB on my macbook and getting it installed and trying to run, so I opted for the optional API source instead of the NoSQL database for the project. I'm not sure if I misinterpreted the requirements for the project or not but I wanted to add my comment on here that I am 'subbing out' NoSQL for API because I'm having trouble with NoSQL. I would be happy to talk to you about it in class if possible!\n",
    "- Also wanted to add that I was havign issues uploading it into my github, so i have provided all files necessary to replicate my project on Canvas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
