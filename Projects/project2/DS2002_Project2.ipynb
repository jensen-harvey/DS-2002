{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-2002 Data Project 2: E-Commerce Dimensional Data Lakehouse\n",
    "Jensen Harvey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Prerequisites\n",
    "### 1.0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, to_date, year, month, dayofmonth, quarter\n",
    "from pyspark.sql.functions import sum as _sum, count as _count, avg as _avg, max as _max, min as _min\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, TimestampType\n",
    "\n",
    "print(\" Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Initialize Spark Session\n",
    "\n",
    "Create local Spark session with necessary configurations for MySQL and MongoDB connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spark Session initialized\n",
      "  Spark Version: 3.5.5\n",
      "  Application ID: local-1766171313547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DS2002-Project2-ECommerce-Lakehouse\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,mysql:mysql-connector-java:8.0.33\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\" Spark Session initialized\")\n",
    "print(f\"  Spark Version: {spark.version}\")\n",
    "print(f\"  Application ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0. Configuration Variables\n",
    "\n",
    "**IMPORTANT:** Update the connection strings below with your actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration complete\n",
      "  Base directory: ./ecommerce_lakehouse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MYSQL_HOST = \"localhost\"\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_USER = \"root\"\n",
    "MYSQL_PASSWORD = \"Jh290917\"  \n",
    "MYSQL_DATABASE = \"ecommerce_source\"\n",
    "\n",
    "\n",
    "MONGODB_USER = \"user_name\"  \n",
    "MONGODB_PASSWORD = \"password\"  \n",
    "MONGODB_CLUSTER = \"cluster_name.xxxxx\"  \n",
    "MONGODB_DATABASE = \"ecommerce\"\n",
    "\n",
    "\n",
    "BASE_DIR = \"./ecommerce_lakehouse\"\n",
    "BRONZE_DIR = f\"{BASE_DIR}/bronze\"\n",
    "SILVER_DIR = f\"{BASE_DIR}/silver\"\n",
    "GOLD_DIR = f\"{BASE_DIR}/gold\"\n",
    "STREAMING_DIR = f\"{BASE_DIR}/streaming\"\n",
    "CHECKPOINT_DIR = f\"{BASE_DIR}/checkpoints\"\n",
    "\n",
    "\n",
    "for directory in [BASE_DIR, BRONZE_DIR, SILVER_DIR, GOLD_DIR, STREAMING_DIR, CHECKPOINT_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\" Configuration complete\")\n",
    "print(f\"  Base directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0. Helper Functions\n",
    "\n",
    "Following Lab 6 pattern for MongoDB connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def get_mongo_dataframe(user_id, pwd, cluster_name, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Fetch data from MongoDB Atlas and return as PySpark DataFrame.\n",
    "    Based on DS-2002 Lab 6 example.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mongo_uri = f\"mongodb+srv://{user_id}:{pwd}@{cluster_name}.mongodb.net/{db_name}\"\n",
    "        \n",
    "        \n",
    "        df = spark.read \\\n",
    "            .format(\"mongo\") \\\n",
    "            .option(\"uri\", mongo_uri) \\\n",
    "            .option(\"database\", db_name) \\\n",
    "            .option(\"collection\", collection_name) \\\n",
    "            .load()\n",
    "        \n",
    "        \n",
    "        if '_id' in df.columns:\n",
    "            df = df.drop('_id')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"MongoDB connection failed: {str(e)[:150]}\")\n",
    "        return None\n",
    "\n",
    "def fetch_mysql_table(table_name):\n",
    "    \"\"\"\n",
    "    Fetch a table from MySQL using JDBC connection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        jdbc_url = f\"jdbc:mysql://{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}\"\n",
    "        \n",
    "        df = spark.read \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", jdbc_url) \\\n",
    "            .option(\"dbtable\", table_name) \\\n",
    "            .option(\"user\", MYSQL_USER) \\\n",
    "            .option(\"password\", MYSQL_PASSWORD) \\\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "            .load()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"MySQL connection failed: {str(e)[:150]}\")\n",
    "        return None\n",
    "\n",
    "print(\" Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Generate Sample Source Data\n",
    "### 5.0. Create Sample Customer Data (MySQL Source Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 15 customer records\n",
      "+-----------+----------+---------+--------------------+-------+-----------+--------------+-------------+-----------------+\n",
      "|customer_id|first_name|last_name|email               |country|city       |state_province|customer_type|registration_date|\n",
      "+-----------+----------+---------+--------------------+-------+-----------+--------------+-------------+-----------------+\n",
      "|1          |John      |Smith    |john.smith@email.com|USA    |New York   |NY            |Customer     |2023-01-15       |\n",
      "|2          |Emma      |Johnson  |emma.j@email.com    |UK     |London     |ENG           |Customer     |2023-02-20       |\n",
      "|3          |Michael   |Brown    |m.brown@email.com   |CANADA |Toronto    |ON            |Customer     |2023-03-10       |\n",
      "|4          |Sophia    |Davis    |sophia.d@email.com  |USA    |Los Angeles|CA            |Premium      |2023-01-05       |\n",
      "|5          |William   |Garcia   |w.garcia@email.com  |SPAIN  |Madrid     |MAD           |Customer     |2023-04-12       |\n",
      "+-----------+----------+---------+--------------------+-------+-----------+--------------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_data = [\n",
    "    (1, \"John\", \"Smith\", \"john.smith@email.com\", \"USA\", \"New York\", \"NY\", \"Customer\", \"2023-01-15\"),\n",
    "    (2, \"Emma\", \"Johnson\", \"emma.j@email.com\", \"UK\", \"London\", \"ENG\", \"Customer\", \"2023-02-20\"),\n",
    "    (3, \"Michael\", \"Brown\", \"m.brown@email.com\", \"CANADA\", \"Toronto\", \"ON\", \"Customer\", \"2023-03-10\"),\n",
    "    (4, \"Sophia\", \"Davis\", \"sophia.d@email.com\", \"USA\", \"Los Angeles\", \"CA\", \"Premium\", \"2023-01-05\"),\n",
    "    (5, \"William\", \"Garcia\", \"w.garcia@email.com\", \"SPAIN\", \"Madrid\", \"MAD\", \"Customer\", \"2023-04-12\"),\n",
    "    (6, \"Olivia\", \"Martinez\", \"olivia.m@email.com\", \"USA\", \"Chicago\", \"IL\", \"Customer\", \"2023-05-18\"),\n",
    "    (7, \"James\", \"Wilson\", \"james.w@email.com\", \"AUSTRALIA\", \"Sydney\", \"NSW\", \"Premium\", \"2023-02-25\"),\n",
    "    (8, \"Isabella\", \"Anderson\", \"i.anderson@email.com\", \"USA\", \"Houston\", \"TX\", \"Customer\", \"2023-06-30\"),\n",
    "    (9, \"Benjamin\", \"Taylor\", \"ben.t@email.com\", \"GERMANY\", \"Berlin\", \"BER\", \"Customer\", \"2023-03-15\"),\n",
    "    (10, \"Mia\", \"Thomas\", \"mia.thomas@email.com\", \"FRANCE\", \"Paris\", \"IDF\", \"Premium\", \"2023-04-20\"),\n",
    "    (11, \"Lucas\", \"Moore\", \"lucas.m@email.com\", \"USA\", \"Phoenix\", \"AZ\", \"Customer\", \"2023-07-05\"),\n",
    "    (12, \"Charlotte\", \"Lee\", \"charlotte.l@email.com\", \"SINGAPORE\", \"Singapore\", \"SG\", \"Customer\", \"2023-08-10\"),\n",
    "    (13, \"Henry\", \"White\", \"h.white@email.com\", \"USA\", \"Philadelphia\", \"PA\", \"Customer\", \"2023-05-22\"),\n",
    "    (14, \"Amelia\", \"Martin\", \"amelia.m@email.com\", \"NETHERLANDS\", \"Amsterdam\", \"NH\", \"Premium\", \"2023-06-15\"),\n",
    "    (15, \"Alexander\", \"Schmidt\", \"alex.s@email.com\", \"SWITZERLAND\", \"Zurich\", \"ZH\", \"Customer\", \"2023-09-01\")\n",
    "]\n",
    "\n",
    "customer_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state_province\", StringType(), True),\n",
    "    StructField(\"customer_type\", StringType(), True),\n",
    "    StructField(\"registration_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_customers_source = spark.createDataFrame(customer_data, customer_schema)\n",
    "\n",
    "\n",
    "df_customers_source.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/customers\")\n",
    "\n",
    "print(f\" Created {df_customers_source.count()} customer records\")\n",
    "df_customers_source.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0. Create Sample Product Data (MongoDB Source Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 10 product records\n",
      "+----------+---------------------------+-----------+-----------+----------+\n",
      "|product_id|product_name               |category   |subcategory|unit_price|\n",
      "+----------+---------------------------+-----------+-----------+----------+\n",
      "|1         |Laptop Pro 15              |Electronics|Computers  |1299.99   |\n",
      "|2         |Wireless Mouse             |Electronics|Accessories|29.99     |\n",
      "|3         |Office Chair Deluxe        |Furniture  |Office     |349.99    |\n",
      "|4         |Standing Desk              |Furniture  |Office     |599.99    |\n",
      "|5         |Noise-Cancelling Headphones|Electronics|Audio      |279.99    |\n",
      "+----------+---------------------------+-----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "product_data = [\n",
    "    (1, \"Laptop Pro 15\", \"Electronics\", \"Computers\", 1299.99),\n",
    "    (2, \"Wireless Mouse\", \"Electronics\", \"Accessories\", 29.99),\n",
    "    (3, \"Office Chair Deluxe\", \"Furniture\", \"Office\", 349.99),\n",
    "    (4, \"Standing Desk\", \"Furniture\", \"Office\", 599.99),\n",
    "    (5, \"Noise-Cancelling Headphones\", \"Electronics\", \"Audio\", 279.99),\n",
    "    (6, \"4K Monitor 27\\\"\", \"Electronics\", \"Displays\", 449.99),\n",
    "    (7, \"Mechanical Keyboard\", \"Electronics\", \"Accessories\", 129.99),\n",
    "    (8, \"Ergonomic Mouse Pad\", \"Electronics\", \"Accessories\", 19.99),\n",
    "    (9, \"Desk Lamp LED\", \"Furniture\", \"Lighting\", 59.99),\n",
    "    (10, \"Bookshelf Oak\", \"Furniture\", \"Storage\", 199.99)\n",
    "]\n",
    "\n",
    "product_schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType(), False),\n",
    "    StructField(\"product_name\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"subcategory\", StringType(), True),\n",
    "    StructField(\"unit_price\", FloatType(), True)\n",
    "])\n",
    "\n",
    "df_products_source = spark.createDataFrame(product_data, product_schema)\n",
    "\n",
    "\n",
    "df_products_source.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/products\")\n",
    "\n",
    "print(f\" Created {df_products_source.count()} product records\")\n",
    "df_products_source.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0. Create Sample Transaction Data for Streaming (3 Batches)\n",
    "\n",
    "This simulates the streaming requirement by creating 3 separate JSON files representing different time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 3 transaction batches for streaming\n",
      "  Batch 1: 7 transactions\n",
      "  Batch 2: 6 transactions\n",
      "  Batch 3: 7 transactions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transaction_batch1 = [\n",
    "    {\"transaction_id\": 1, \"customer_id\": 1, \"product_id\": 1, \"quantity\": 1, \"transaction_date\": \"2024-01-15\", \"currency\": \"USD\", \"shipping_cost\": 15.00},\n",
    "    {\"transaction_id\": 2, \"customer_id\": 2, \"product_id\": 3, \"quantity\": 1, \"transaction_date\": \"2024-01-16\", \"currency\": \"GBP\", \"shipping_cost\": 25.00},\n",
    "    {\"transaction_id\": 3, \"customer_id\": 3, \"product_id\": 5, \"quantity\": 2, \"transaction_date\": \"2024-01-17\", \"currency\": \"CAD\", \"shipping_cost\": 20.00},\n",
    "    {\"transaction_id\": 4, \"customer_id\": 4, \"product_id\": 6, \"quantity\": 1, \"transaction_date\": \"2024-01-18\", \"currency\": \"USD\", \"shipping_cost\": 12.00},\n",
    "    {\"transaction_id\": 5, \"customer_id\": 5, \"product_id\": 2, \"quantity\": 3, \"transaction_date\": \"2024-01-19\", \"currency\": \"EUR\", \"shipping_cost\": 18.00},\n",
    "    {\"transaction_id\": 6, \"customer_id\": 1, \"product_id\": 7, \"quantity\": 1, \"transaction_date\": \"2024-01-20\", \"currency\": \"USD\", \"shipping_cost\": 10.00},\n",
    "    {\"transaction_id\": 7, \"customer_id\": 8, \"product_id\": 8, \"quantity\": 2, \"transaction_date\": \"2024-01-21\", \"currency\": \"USD\", \"shipping_cost\": 8.00}\n",
    "]\n",
    "\n",
    "transaction_batch2 = [\n",
    "    {\"transaction_id\": 8, \"customer_id\": 9, \"product_id\": 4, \"quantity\": 1, \"transaction_date\": \"2024-02-01\", \"currency\": \"EUR\", \"shipping_cost\": 30.00},\n",
    "    {\"transaction_id\": 9, \"customer_id\": 10, \"product_id\": 5, \"quantity\": 1, \"transaction_date\": \"2024-02-02\", \"currency\": \"EUR\", \"shipping_cost\": 22.00},\n",
    "    {\"transaction_id\": 10, \"customer_id\": 2, \"product_id\": 9, \"quantity\": 2, \"transaction_date\": \"2024-02-03\", \"currency\": \"GBP\", \"shipping_cost\": 15.00},\n",
    "    {\"transaction_id\": 11, \"customer_id\": 11, \"product_id\": 1, \"quantity\": 1, \"transaction_date\": \"2024-02-04\", \"currency\": \"USD\", \"shipping_cost\": 15.00},\n",
    "    {\"transaction_id\": 12, \"customer_id\": 3, \"product_id\": 10, \"quantity\": 1, \"transaction_date\": \"2024-02-05\", \"currency\": \"CAD\", \"shipping_cost\": 25.00},\n",
    "    {\"transaction_id\": 13, \"customer_id\": 12, \"product_id\": 6, \"quantity\": 1, \"transaction_date\": \"2024-02-06\", \"currency\": \"SGD\", \"shipping_cost\": 20.00}\n",
    "]\n",
    "\n",
    "transaction_batch3 = [\n",
    "    {\"transaction_id\": 14, \"customer_id\": 4, \"product_id\": 2, \"quantity\": 4, \"transaction_date\": \"2024-03-01\", \"currency\": \"USD\", \"shipping_cost\": 12.00},\n",
    "    {\"transaction_id\": 15, \"customer_id\": 13, \"product_id\": 7, \"quantity\": 1, \"transaction_date\": \"2024-03-02\", \"currency\": \"USD\", \"shipping_cost\": 10.00},\n",
    "    {\"transaction_id\": 16, \"customer_id\": 14, \"product_id\": 3, \"quantity\": 1, \"transaction_date\": \"2024-03-03\", \"currency\": \"EUR\", \"shipping_cost\": 28.00},\n",
    "    {\"transaction_id\": 17, \"customer_id\": 15, \"product_id\": 8, \"quantity\": 5, \"transaction_date\": \"2024-03-04\", \"currency\": \"CHF\", \"shipping_cost\": 18.00},\n",
    "    {\"transaction_id\": 18, \"customer_id\": 1, \"product_id\": 4, \"quantity\": 1, \"transaction_date\": \"2024-03-05\", \"currency\": \"USD\", \"shipping_cost\": 30.00},\n",
    "    {\"transaction_id\": 19, \"customer_id\": 7, \"product_id\": 5, \"quantity\": 1, \"transaction_date\": \"2024-03-06\", \"currency\": \"AUD\", \"shipping_cost\": 25.00},\n",
    "    {\"transaction_id\": 20, \"customer_id\": 6, \"product_id\": 9, \"quantity\": 3, \"transaction_date\": \"2024-03-07\", \"currency\": \"USD\", \"shipping_cost\": 15.00}\n",
    "]\n",
    "\n",
    "\n",
    "os.makedirs(f\"{STREAMING_DIR}/transactions\", exist_ok=True)\n",
    "\n",
    "with open(f\"{STREAMING_DIR}/transactions/batch1.json\", 'w') as f:\n",
    "    for record in transaction_batch1:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "with open(f\"{STREAMING_DIR}/transactions/batch2.json\", 'w') as f:\n",
    "    for record in transaction_batch2:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "with open(f\"{STREAMING_DIR}/transactions/batch3.json\", 'w') as f:\n",
    "    for record in transaction_batch3:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "print(\" Created 3 transaction batches for streaming\")\n",
    "print(f\"  Batch 1: {len(transaction_batch1)} transactions\")\n",
    "print(f\"  Batch 2: {len(transaction_batch2)} transactions\")\n",
    "print(f\"  Batch 3: {len(transaction_batch3)} transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0. Fetch Real-Time Exchange Rate Data (REST API)\n",
    "\n",
    "This demonstrates integration with an external API for real-time reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetched real-time exchange rates from API\n",
      " Created exchange rate reference with 166 currencies\n",
      "+--------+-----------+\n",
      "|currency|rate_to_usd|\n",
      "+--------+-----------+\n",
      "|     USD|        1.0|\n",
      "|     AED|       3.67|\n",
      "|     AFN|      66.24|\n",
      "|     ALL|      82.32|\n",
      "|     AMD|     381.58|\n",
      "|     ANG|       1.79|\n",
      "|     AOA|     920.99|\n",
      "|     ARS|    1453.17|\n",
      "|     AUD|       1.51|\n",
      "|     AWG|       1.79|\n",
      "|     AZN|        1.7|\n",
      "|     BAM|       1.67|\n",
      "|     BBD|        2.0|\n",
      "|     BDT|     122.26|\n",
      "|     BGN|       1.67|\n",
      "|     BHD|      0.376|\n",
      "|     BIF|    2963.42|\n",
      "|     BMD|        1.0|\n",
      "|     BND|       1.29|\n",
      "|     BOB|       6.91|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_exchange_rates():\n",
    "    \"\"\"\n",
    "    Fetch current exchange rates from API.\n",
    "    Falls back to static rates if API unavailable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            rates = response.json()['rates']\n",
    "            print(\" Fetched real-time exchange rates from API\")\n",
    "        else:\n",
    "            raise Exception(\"API request failed\")\n",
    "    except:\n",
    "       \n",
    "        rates = {\n",
    "            'USD': 1.0,\n",
    "            'EUR': 0.92,\n",
    "            'GBP': 0.79,\n",
    "            'CAD': 1.36,\n",
    "            'AUD': 1.52,\n",
    "            'CHF': 0.88,\n",
    "            'SGD': 1.34\n",
    "        }\n",
    "        print(\" Using static exchange rates (API unavailable)\")\n",
    "    \n",
    "    return rates\n",
    "\n",
    "exchange_rates = get_exchange_rates()\n",
    "\n",
    "\n",
    "rate_data = [(currency, float(rate)) for currency, rate in exchange_rates.items()]\n",
    "rate_schema = StructType([\n",
    "    StructField(\"currency\", StringType(), False),\n",
    "    StructField(\"rate_to_usd\", FloatType(), True)\n",
    "])\n",
    "\n",
    "df_exchange_rates = spark.createDataFrame(rate_data, rate_schema)\n",
    "df_exchange_rates.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/exchange_rates\")\n",
    "\n",
    "print(f\" Created exchange rate reference with {df_exchange_rates.count()} currencies\")\n",
    "df_exchange_rates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Bronze Layer - Raw Data Ingestion\n",
    "### 9.0. Load All Bronze Data\n",
    "\n",
    "Demonstrating batch load from multiple source types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bronze layer loaded\n",
      "  Customers: 15 records\n",
      "  Products: 10 records\n",
      "  Exchange Rates: 166 currencies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_customers_bronze = spark.read.parquet(f\"{BRONZE_DIR}/customers\")\n",
    "df_products_bronze = spark.read.parquet(f\"{BRONZE_DIR}/products\")\n",
    "df_rates_bronze = spark.read.parquet(f\"{BRONZE_DIR}/exchange_rates\")\n",
    "\n",
    "\n",
    "df_customers_bronze.createOrReplaceTempView(\"customers_bronze\")\n",
    "df_products_bronze.createOrReplaceTempView(\"products_bronze\")\n",
    "df_rates_bronze.createOrReplaceTempView(\"exchange_rates_bronze\")\n",
    "\n",
    "print(\" Bronze layer loaded\")\n",
    "print(f\"  Customers: {df_customers_bronze.count()} records\")\n",
    "print(f\"  Products: {df_products_bronze.count()} records\")\n",
    "print(f\"  Exchange Rates: {df_rates_bronze.count()} currencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Structured Streaming - Bronze to Silver\n",
    "### 10.0. Setup Streaming Schema for Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Transaction schema defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transaction_schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"transaction_date\", StringType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"shipping_cost\", FloatType(), True)\n",
    "])\n",
    "\n",
    "print(\" Transaction schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.0. Read Streaming Data (Bronze Layer)\n",
    "\n",
    "This simulates Spark AutoLoader functionality using readStream with JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streaming source configured\n",
      "  Reading from: ./ecommerce_lakehouse/streaming/transactions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_transactions_stream = spark.readStream \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(transaction_schema) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .load(f\"{STREAMING_DIR}/transactions\")\n",
    "\n",
    "\n",
    "df_transactions_bronze_stream = df_transactions_stream \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "\n",
    "print(\" Streaming source configured\")\n",
    "print(f\"  Reading from: {STREAMING_DIR}/transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.0. Write Bronze Stream to Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bronze streaming query started\n",
      "  Checkpoint: ./ecommerce_lakehouse/checkpoints/transactions_bronze\n",
      "  Output: ./ecommerce_lakehouse/bronze/transactions_stream\n",
      "\n",
      " Processing streaming data (this will take ~15-20 seconds)...\n",
      " Bronze streaming completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_bronze = df_transactions_bronze_stream.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"checkpointLocation\", f\"{CHECKPOINT_DIR}/transactions_bronze\") \\\n",
    "    .option(\"path\", f\"{BRONZE_DIR}/transactions_stream\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "print(\" Bronze streaming query started\")\n",
    "print(f\"  Checkpoint: {CHECKPOINT_DIR}/transactions_bronze\")\n",
    "print(f\"  Output: {BRONZE_DIR}/transactions_stream\")\n",
    "\n",
    "\n",
    "import time\n",
    "print(\"\\n Processing streaming data (this will take ~15-20 seconds)...\")\n",
    "time.sleep(20)\n",
    "\n",
    "\n",
    "query_bronze.stop()\n",
    "print(\" Bronze streaming completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section V: Silver Layer - Data Cleansing and Integration\n",
    "### 13.0. Transform Customer Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Customer dimension transformed\n",
      "+-----------+-----------------+---------------------+-----------+------------+--------------+-------------+-----------------+\n",
      "|customer_id|full_name        |email                |country    |city        |state_province|customer_type|registration_date|\n",
      "+-----------+-----------------+---------------------+-----------+------------+--------------+-------------+-----------------+\n",
      "|12         |Charlotte Lee    |charlotte.l@email.com|SINGAPORE  |Singapore   |SG            |Customer     |2023-08-10       |\n",
      "|13         |Henry White      |h.white@email.com    |USA        |Philadelphia|PA            |Customer     |2023-05-22       |\n",
      "|8          |Isabella Anderson|i.anderson@email.com |USA        |Houston     |TX            |Customer     |2023-06-30       |\n",
      "|9          |Benjamin Taylor  |ben.t@email.com      |GERMANY    |Berlin      |BER           |Customer     |2023-03-15       |\n",
      "|14         |Amelia Martin    |amelia.m@email.com   |NETHERLANDS|Amsterdam   |NH            |Premium      |2023-06-15       |\n",
      "+-----------+-----------------+---------------------+-----------+------------+--------------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import concat_ws, upper\n",
    "\n",
    "df_customers_silver = df_customers_bronze \\\n",
    "    .withColumn(\"full_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\"))) \\\n",
    "    .withColumn(\"country\", upper(col(\"country\"))) \\\n",
    "    .select(\n",
    "        \"customer_id\",\n",
    "        \"full_name\",\n",
    "        \"email\",\n",
    "        \"country\",\n",
    "        \"city\",\n",
    "        \"state_province\",\n",
    "        \"customer_type\",\n",
    "        \"registration_date\"\n",
    "    )\n",
    "\n",
    "\n",
    "df_customers_silver.write.mode(\"overwrite\").parquet(f\"{SILVER_DIR}/customers\")\n",
    "df_customers_silver.createOrReplaceTempView(\"customers_silver\")\n",
    "\n",
    "print(\" Customer dimension transformed\")\n",
    "df_customers_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.0. Transform Product Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Product dimension transformed\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "|product_id|product_name       |category   |subcategory|unit_price|\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "|8         |Ergonomic Mouse Pad|Electronics|Accessories|19.99     |\n",
      "|7         |Mechanical Keyboard|Electronics|Accessories|129.99    |\n",
      "|2         |Wireless Mouse     |Electronics|Accessories|29.99     |\n",
      "|3         |Office Chair Deluxe|Furniture  |Office     |349.99    |\n",
      "|6         |4K Monitor 27\"     |Electronics|Displays   |449.99    |\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_products_silver = df_products_bronze.select(\n",
    "    \"product_id\",\n",
    "    \"product_name\",\n",
    "    \"category\",\n",
    "    \"subcategory\",\n",
    "    \"unit_price\"\n",
    ")\n",
    "\n",
    "\n",
    "df_products_silver.write.mode(\"overwrite\").parquet(f\"{SILVER_DIR}/products\")\n",
    "df_products_silver.createOrReplaceTempView(\"products_silver\")\n",
    "\n",
    "print(\" Product dimension transformed\")\n",
    "df_products_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.0. Transform Transaction Fact (Join with Reference Data)\n",
    "\n",
    "This demonstrates joining streaming fact data with static reference data (Silver layer pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Read 20 transactions from bronze stream\n",
      " Transaction fact transformed and joined with reference data\n",
      "  Total records: 20\n",
      "+--------------+----------------+-----------+----------+--------+--------+----------+-------------+------------------+------------------+-----------------------+\n",
      "|transaction_id|transaction_date|customer_id|product_id|quantity|currency|unit_price|shipping_cost|total_amount_local|total_amount_usd  |ingestion_timestamp    |\n",
      "+--------------+----------------+-----------+----------+--------+--------+----------+-------------+------------------+------------------+-----------------------+\n",
      "|14            |2024-03-01      |4          |2         |4       |USD     |29.99     |12.0         |131.95999         |131.95999145507812|2025-12-18 14:19:25.094|\n",
      "|15            |2024-03-02      |13         |7         |1       |USD     |129.99    |10.0         |139.99            |139.99000549316406|2025-12-18 14:19:25.094|\n",
      "|16            |2024-03-03      |14         |3         |1       |EUR     |349.99    |28.0         |377.99            |443.1301251872253 |2025-12-18 14:19:25.094|\n",
      "|17            |2024-03-04      |15         |8         |5       |CHF     |19.99     |18.0         |117.95            |148.5516279048818 |2025-12-18 14:19:25.094|\n",
      "|18            |2024-03-05      |1          |4         |1       |USD     |599.99    |30.0         |629.99            |629.989990234375  |2025-12-18 14:19:25.094|\n",
      "+--------------+----------------+-----------+----------+--------+--------+----------+-------------+------------------+------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_transactions_bronze = spark.read.parquet(f\"{BRONZE_DIR}/transactions_stream\")\n",
    "\n",
    "print(f\" Read {df_transactions_bronze.count()} transactions from bronze stream\")\n",
    "\n",
    "\n",
    "df_transactions_with_price = df_transactions_bronze \\\n",
    "    .join(df_products_silver, \"product_id\", \"left\")\n",
    "\n",
    "df_transactions_with_price = df_transactions_with_price \\\n",
    "    .withColumnRenamed(\"currency\", \"transaction_currency\")\n",
    "\n",
    "\n",
    "df_transactions_silver = df_transactions_with_price \\\n",
    "    .join(df_rates_bronze, \n",
    "          df_transactions_with_price.transaction_currency == df_rates_bronze.currency, \n",
    "          \"left\") \\\n",
    "    .withColumn(\"total_amount_local\", \n",
    "                (col(\"quantity\") * col(\"unit_price\")) + col(\"shipping_cost\")) \\\n",
    "    .withColumn(\"total_amount_usd\", \n",
    "                col(\"total_amount_local\") / col(\"rate_to_usd\")) \\\n",
    "    .select(\n",
    "        \"transaction_id\",\n",
    "        \"transaction_date\",\n",
    "        \"customer_id\",\n",
    "        \"product_id\",\n",
    "        \"quantity\",\n",
    "        col(\"transaction_currency\").alias(\"currency\"),\n",
    "        \"unit_price\",\n",
    "        \"shipping_cost\",\n",
    "        \"total_amount_local\",\n",
    "        \"total_amount_usd\",\n",
    "        \"ingestion_timestamp\"\n",
    "    )\n",
    "\n",
    "\n",
    "df_transactions_silver.write.mode(\"overwrite\").parquet(f\"{SILVER_DIR}/transactions\")\n",
    "df_transactions_silver.createOrReplaceTempView(\"transactions_silver\")\n",
    "\n",
    "print(\" Transaction fact transformed and joined with reference data\")\n",
    "print(f\"  Total records: {df_transactions_silver.count()}\")\n",
    "df_transactions_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section VI: Gold Layer - Dimensional Model\n",
    "### 16.0. Create Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Date dimension created with 731 dates\n",
      "+----------+----------+----+-----+---+-------+-----------+------------+\n",
      "|      date|   date_id|year|month|day|quarter|day_of_week|week_of_year|\n",
      "+----------+----------+----+-----+---+-------+-----------+------------+\n",
      "|2023-01-01|2023-01-01|2023|    1|  1|      1|          1|          52|\n",
      "|2023-01-02|2023-01-02|2023|    1|  2|      1|          2|           1|\n",
      "|2023-01-03|2023-01-03|2023|    1|  3|      1|          3|           1|\n",
      "|2023-01-04|2023-01-04|2023|    1|  4|      1|          4|           1|\n",
      "|2023-01-05|2023-01-05|2023|    1|  5|      1|          5|           1|\n",
      "+----------+----------+----+-----+---+-------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import date, timedelta\n",
    "from pyspark.sql.functions import dayofweek, quarter, weekofyear\n",
    "\n",
    "start_date = date(2023, 1, 1)\n",
    "end_date = date(2024, 12, 31)\n",
    "\n",
    "date_list = []\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    date_list.append((current_date,))\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "df_dates_temp = spark.createDataFrame(date_list, [\"date\"])\n",
    "\n",
    "df_dim_date = df_dates_temp \\\n",
    "    .withColumn(\"date_id\", col(\"date\").cast(\"string\").substr(1, 10).cast(\"string\")) \\\n",
    "    .withColumn(\"year\", year(col(\"date\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"date\"))) \\\n",
    "    .withColumn(\"day\", dayofmonth(col(\"date\"))) \\\n",
    "    .withColumn(\"quarter\", quarter(col(\"date\"))) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"date\"))) \\\n",
    "    .withColumn(\"week_of_year\", weekofyear(col(\"date\")))\n",
    "\n",
    "\n",
    "df_dim_date.write.mode(\"overwrite\").parquet(f\"{GOLD_DIR}/dim_date\")\n",
    "df_dim_date.createOrReplaceTempView(\"dim_date\")\n",
    "\n",
    "print(f\" Date dimension created with {df_dim_date.count()} dates\")\n",
    "df_dim_date.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.0. Create Customer Dimension (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Customer dimension created with 15 customers\n",
      "+-----------+-----------------+---------------------+-----------+------------+-------------+\n",
      "|customer_id|full_name        |email                |country    |city        |customer_type|\n",
      "+-----------+-----------------+---------------------+-----------+------------+-------------+\n",
      "|12         |Charlotte Lee    |charlotte.l@email.com|SINGAPORE  |Singapore   |Customer     |\n",
      "|13         |Henry White      |h.white@email.com    |USA        |Philadelphia|Customer     |\n",
      "|8          |Isabella Anderson|i.anderson@email.com |USA        |Houston     |Customer     |\n",
      "|9          |Benjamin Taylor  |ben.t@email.com      |GERMANY    |Berlin      |Customer     |\n",
      "|14         |Amelia Martin    |amelia.m@email.com   |NETHERLANDS|Amsterdam   |Premium      |\n",
      "+-----------+-----------------+---------------------+-----------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dim_customer = df_customers_silver.select(\n",
    "    \"customer_id\",\n",
    "    \"full_name\",\n",
    "    \"email\",\n",
    "    \"country\",\n",
    "    \"city\",\n",
    "    \"customer_type\"\n",
    ")\n",
    "\n",
    "\n",
    "df_dim_customer.write.mode(\"overwrite\").parquet(f\"{GOLD_DIR}/dim_customer\")\n",
    "df_dim_customer.createOrReplaceTempView(\"dim_customer\")\n",
    "\n",
    "print(f\" Customer dimension created with {df_dim_customer.count()} customers\")\n",
    "df_dim_customer.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.0. Create Product Dimension (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Product dimension created with 10 products\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "|product_id|product_name       |category   |subcategory|unit_price|\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "|8         |Ergonomic Mouse Pad|Electronics|Accessories|19.99     |\n",
      "|7         |Mechanical Keyboard|Electronics|Accessories|129.99    |\n",
      "|2         |Wireless Mouse     |Electronics|Accessories|29.99     |\n",
      "|3         |Office Chair Deluxe|Furniture  |Office     |349.99    |\n",
      "|6         |4K Monitor 27\"     |Electronics|Displays   |449.99    |\n",
      "+----------+-------------------+-----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dim_product = df_products_silver.select(\n",
    "    \"product_id\",\n",
    "    \"product_name\",\n",
    "    \"category\",\n",
    "    \"subcategory\",\n",
    "    \"unit_price\"\n",
    ")\n",
    "\n",
    "\n",
    "df_dim_product.write.mode(\"overwrite\").parquet(f\"{GOLD_DIR}/dim_product\")\n",
    "df_dim_product.createOrReplaceTempView(\"dim_product\")\n",
    "\n",
    "print(f\" Product dimension created with {df_dim_product.count()} products\")\n",
    "df_dim_product.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.0. Create Sales Fact Table (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sales fact table created with 20 transactions\n",
      "+--------------+----------+-----------+----------+--------+----------+-------------+------------------+\n",
      "|transaction_id|   date_id|customer_id|product_id|quantity|unit_price|shipping_cost|  total_amount_usd|\n",
      "+--------------+----------+-----------+----------+--------+----------+-------------+------------------+\n",
      "|            14|2024-03-01|          4|         2|       4|     29.99|         12.0|131.95999145507812|\n",
      "|            15|2024-03-02|         13|         7|       1|    129.99|         10.0|139.99000549316406|\n",
      "|            16|2024-03-03|         14|         3|       1|    349.99|         28.0| 443.1301251872253|\n",
      "|            17|2024-03-04|         15|         8|       5|     19.99|         18.0| 148.5516279048818|\n",
      "|            18|2024-03-05|          1|         4|       1|    599.99|         30.0|  629.989990234375|\n",
      "+--------------+----------+-----------+----------+--------+----------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_fact_sales = df_transactions_silver \\\n",
    "    .withColumn(\"date_id\", to_date(col(\"transaction_date\")).cast(\"string\")) \\\n",
    "    .select(\n",
    "        \"transaction_id\",\n",
    "        \"date_id\",\n",
    "        \"customer_id\",\n",
    "        \"product_id\",\n",
    "        \"quantity\",\n",
    "        \"unit_price\",\n",
    "        \"shipping_cost\",\n",
    "        \"total_amount_usd\"\n",
    "    )\n",
    "\n",
    "\n",
    "df_fact_sales.write.mode(\"overwrite\").parquet(f\"{GOLD_DIR}/fact_sales\")\n",
    "df_fact_sales.createOrReplaceTempView(\"fact_sales\")\n",
    "\n",
    "print(f\" Sales fact table created with {df_fact_sales.count()} transactions\")\n",
    "df_fact_sales.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section VII: Business Intelligence Queries (Demonstrating Business Value)\n",
    "### 20.0. Query 1: Sales by Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BUSINESS QUERY 1: Sales Performance by Customer\n",
      "================================================================================\n",
      "+-----------+---------------+-----------+-------------+----------+-----------+-----------------+\n",
      "|customer_id|full_name      |country    |customer_type|num_orders|total_items|total_revenue_usd|\n",
      "+-----------+---------------+-----------+-------------+----------+-----------+-----------------+\n",
      "|1          |John Smith     |USA        |Customer     |3         |3          |2084.97          |\n",
      "|11         |Lucas Moore    |USA        |Customer     |1         |1          |1314.99          |\n",
      "|9          |Benjamin Taylor|GERMANY    |Customer     |1         |1          |738.56           |\n",
      "|2          |Emma Johnson   |UK         |Customer     |2         |3          |682.69           |\n",
      "|4          |Sophia Davis   |USA        |Premium      |2         |5          |593.95           |\n",
      "|3          |Michael Brown  |CANADA     |Customer     |2         |3          |583.31           |\n",
      "|14         |Amelia Martin  |NETHERLANDS|Premium      |1         |1          |443.13           |\n",
      "|12         |Charlotte Lee  |SINGAPORE  |Customer     |1         |1          |364.33           |\n",
      "|10         |Mia Thomas     |FRANCE     |Premium      |1         |1          |354.03           |\n",
      "|7          |James Wilson   |AUSTRALIA  |Premium      |1         |1          |201.98           |\n",
      "+-----------+---------------+-----------+-------------+----------+-----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query1 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.full_name,\n",
    "        c.country,\n",
    "        c.customer_type,\n",
    "        COUNT(f.transaction_id) as num_orders,\n",
    "        SUM(f.quantity) as total_items,\n",
    "        ROUND(SUM(f.total_amount_usd), 2) as total_revenue_usd\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.customer_id = c.customer_id\n",
    "    GROUP BY c.customer_id, c.full_name, c.country, c.customer_type\n",
    "    ORDER BY total_revenue_usd DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n BUSINESS QUERY 1: Sales Performance by Customer\")\n",
    "print(\"=\"*80)\n",
    "query1.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.0. Query 2: Sales by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BUSINESS QUERY 2: Sales Performance by Product Category\n",
      "================================================================================\n",
      "+-----------+----------------+----------------+---------------------+-----------------+\n",
      "|category   |num_transactions|total_units_sold|avg_transaction_value|total_revenue_usd|\n",
      "+-----------+----------------+----------------+---------------------+-----------------+\n",
      "|Electronics|13              |24              |397.51               |5167.64          |\n",
      "|Furniture  |7               |10              |407.48               |2852.38          |\n",
      "+-----------+----------------+----------------+---------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query2 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.category,\n",
    "        COUNT(DISTINCT f.transaction_id) as num_transactions,\n",
    "        SUM(f.quantity) as total_units_sold,\n",
    "        ROUND(AVG(f.total_amount_usd), 2) as avg_transaction_value,\n",
    "        ROUND(SUM(f.total_amount_usd), 2) as total_revenue_usd\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_product p ON f.product_id = p.product_id\n",
    "    GROUP BY p.category\n",
    "    ORDER BY total_revenue_usd DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n BUSINESS QUERY 2: Sales Performance by Product Category\")\n",
    "print(\"=\"*80)\n",
    "query2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.0. Query 3: Monthly Sales Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BUSINESS QUERY 3: Monthly Sales Trends\n",
      "================================================================================\n",
      "+----+-----+-------+----------------+-----------------+---------------+\n",
      "|year|month|quarter|num_transactions|total_revenue_usd|avg_order_value|\n",
      "+----+-----+-------+----------------+-----------------+---------------+\n",
      "|2024|1    |1      |7               |3013.8           |430.54         |\n",
      "|2024|2    |1      |6               |3115.65          |519.27         |\n",
      "|2024|3    |1      |7               |1890.57          |270.08         |\n",
      "+----+-----+-------+----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query3 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        d.year,\n",
    "        d.month,\n",
    "        d.quarter,\n",
    "        COUNT(f.transaction_id) as num_transactions,\n",
    "        ROUND(SUM(f.total_amount_usd), 2) as total_revenue_usd,\n",
    "        ROUND(AVG(f.total_amount_usd), 2) as avg_order_value\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_date d ON f.date_id = d.date_id\n",
    "    GROUP BY d.year, d.month, d.quarter\n",
    "    ORDER BY d.year, d.month\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n BUSINESS QUERY 3: Monthly Sales Trends\")\n",
    "print(\"=\"*80)\n",
    "query3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.0. Query 4: Top Products by Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BUSINESS QUERY 4: Top 10 Products by Revenue\n",
      "================================================================================\n",
      "+----------+---------------------------+-----------+-------------+----------------+-----------------+\n",
      "|product_id|product_name               |category   |times_ordered|total_units_sold|total_revenue_usd|\n",
      "+----------+---------------------------+-----------+-------------+----------------+-----------------+\n",
      "|1         |Laptop Pro 15              |Electronics|2            |2               |2629.98          |\n",
      "|4         |Standing Desk              |Furniture  |2            |2               |1368.55          |\n",
      "|5         |Noise-Cancelling Headphones|Electronics|3            |4               |976.29           |\n",
      "|3         |Office Chair Deluxe        |Furniture  |2            |2               |945.12           |\n",
      "|6         |4K Monitor 27\"             |Electronics|2            |2               |826.32           |\n",
      "|9         |Desk Lamp LED              |Furniture  |2            |5               |375.67           |\n",
      "|7         |Mechanical Keyboard        |Electronics|2            |2               |279.98           |\n",
      "|2         |Wireless Mouse             |Electronics|2            |7               |258.54           |\n",
      "|8         |Ergonomic Mouse Pad        |Electronics|2            |7               |196.53           |\n",
      "|10        |Bookshelf Oak              |Furniture  |1            |1               |163.04           |\n",
      "+----------+---------------------------+-----------+-------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query4 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        p.product_name,\n",
    "        p.category,\n",
    "        COUNT(f.transaction_id) as times_ordered,\n",
    "        SUM(f.quantity) as total_units_sold,\n",
    "        ROUND(SUM(f.total_amount_usd), 2) as total_revenue_usd\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_product p ON f.product_id = p.product_id\n",
    "    GROUP BY p.product_id, p.product_name, p.category\n",
    "    ORDER BY total_revenue_usd DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n BUSINESS QUERY 4: Top 10 Products by Revenue\")\n",
    "print(\"=\"*80)\n",
    "query4.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.0. Query 5: Geographic Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BUSINESS QUERY 5: Sales Performance by Country\n",
      "================================================================================\n",
      "+-----------+-------------+----------+-----------+-----------------+---------------+\n",
      "|country    |num_customers|num_orders|total_items|total_revenue_usd|avg_order_value|\n",
      "+-----------+-------------+----------+-----------+-----------------+---------------+\n",
      "|USA        |6            |9         |15         |4376.85          |486.32         |\n",
      "|GERMANY    |1            |1         |1          |738.56           |738.56         |\n",
      "|UK         |1            |2         |3          |682.69           |341.35         |\n",
      "|CANADA     |1            |2         |3          |583.31           |291.66         |\n",
      "|NETHERLANDS|1            |1         |1          |443.13           |443.13         |\n",
      "|SINGAPORE  |1            |1         |1          |364.33           |364.33         |\n",
      "|FRANCE     |1            |1         |1          |354.03           |354.03         |\n",
      "|AUSTRALIA  |1            |1         |1          |201.98           |201.98         |\n",
      "|SWITZERLAND|1            |1         |5          |148.55           |148.55         |\n",
      "|SPAIN      |1            |1         |3          |126.58           |126.58         |\n",
      "+-----------+-------------+----------+-----------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query5 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.country,\n",
    "        COUNT(DISTINCT c.customer_id) as num_customers,\n",
    "        COUNT(f.transaction_id) as num_orders,\n",
    "        SUM(f.quantity) as total_items,\n",
    "        ROUND(SUM(f.total_amount_usd), 2) as total_revenue_usd,\n",
    "        ROUND(AVG(f.total_amount_usd), 2) as avg_order_value\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.customer_id = c.customer_id\n",
    "    GROUP BY c.country\n",
    "    ORDER BY total_revenue_usd DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n BUSINESS QUERY 5: Sales Performance by Country\")\n",
    "print(\"=\"*80)\n",
    "query5.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section VIII: Demonstrate Incremental Batch Load\n",
    "### 25.0. Simulate Additional Customer Data (Incremental Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INCREMENTAL BATCH LOAD: Adding New Customers\n",
      "================================================================================\n",
      " Created 3 new customer records\n",
      "+-----------+----------+---------+---------------------+-------+---------+--------------+-------------+-----------------+\n",
      "|customer_id|first_name|last_name|email                |country|city     |state_province|customer_type|registration_date|\n",
      "+-----------+----------+---------+---------------------+-------+---------+--------------+-------------+-----------------+\n",
      "|16         |Sophie    |Chen     |sophie.chen@email.com|CHINA  |Shanghai |SH            |Premium      |2024-10-01       |\n",
      "|17         |Marco     |Rossi    |m.rossi@email.com    |ITALY  |Rome     |RM            |Customer     |2024-10-05       |\n",
      "|18         |Ana       |Silva    |ana.silva@email.com  |BRAZIL |Sao Paulo|SP            |Customer     |2024-10-10       |\n",
      "+-----------+----------+---------+---------------------+-------+---------+--------------+-------------+-----------------+\n",
      "\n",
      "\n",
      " Incremental load complete\n",
      "  Total customers now: 18\n",
      "  Previous count: 15\n",
      "  New customers added: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_customer_data = [\n",
    "    (16, \"Sophie\", \"Chen\", \"sophie.chen@email.com\", \"CHINA\", \"Shanghai\", \"SH\", \"Premium\", \"2024-10-01\"),\n",
    "    (17, \"Marco\", \"Rossi\", \"m.rossi@email.com\", \"ITALY\", \"Rome\", \"RM\", \"Customer\", \"2024-10-05\"),\n",
    "    (18, \"Ana\", \"Silva\", \"ana.silva@email.com\", \"BRAZIL\", \"Sao Paulo\", \"SP\", \"Customer\", \"2024-10-10\")\n",
    "]\n",
    "\n",
    "df_new_customers = spark.createDataFrame(new_customer_data, customer_schema)\n",
    "\n",
    "print(\"\\n INCREMENTAL BATCH LOAD: Adding New Customers\")\n",
    "print(\"=\"*80)\n",
    "print(f\" Created {df_new_customers.count()} new customer records\")\n",
    "df_new_customers.show(truncate=False)\n",
    "\n",
    "\n",
    "df_all_customers = df_customers_bronze.union(df_new_customers)\n",
    "\n",
    "\n",
    "df_customers_silver_updated = df_all_customers \\\n",
    "    .withColumn(\"full_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\"))) \\\n",
    "    .withColumn(\"country\", upper(col(\"country\"))) \\\n",
    "    .select(\n",
    "        \"customer_id\", \"full_name\", \"email\", \"country\", \n",
    "        \"city\", \"state_province\", \"customer_type\", \"registration_date\"\n",
    "    )\n",
    "\n",
    "\n",
    "df_customers_silver_updated.write.mode(\"overwrite\").parquet(f\"{SILVER_DIR}/customers\")\n",
    "df_customers_silver_updated.select(\n",
    "    \"customer_id\", \"full_name\", \"email\", \"country\", \"city\", \"customer_type\"\n",
    ").write.mode(\"overwrite\").parquet(f\"{GOLD_DIR}/dim_customer\")\n",
    "\n",
    "print(f\"\\n Incremental load complete\")\n",
    "print(f\"  Total customers now: {df_customers_silver_updated.count()}\")\n",
    "print(f\"  Previous count: {df_customers_silver.count()}\")\n",
    "print(f\"  New customers added: {df_new_customers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IX: Summary and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.0. Verify Data Lakehouse Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATA LAKEHOUSE DIRECTORY STRUCTURE:\n",
      "================================================================================\n",
      "./ecommerce_lakehouse\n",
      " bronze\n",
      "    currency_rates.csv\n",
      "    customers\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00001-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00002-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00003-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00004-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00005-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00006-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       .part-00007-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00001-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00002-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00003-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00004-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00005-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00006-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "       part-00007-1ae67625-811e-45c1-9f38-037b7153d539-c000.snappy.parquet\n",
      "    customers.csv\n",
      "    exchange_rates\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00001-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00002-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00003-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00004-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00005-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00006-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       .part-00007-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00001-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00002-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00003-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00004-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00005-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00006-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "       part-00007-e8479a33-089b-41ed-9e8e-192a31dc718c-c000.snappy.parquet\n",
      "    products\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00001-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00002-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00003-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00004-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00005-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00006-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       .part-00007-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00001-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00002-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00003-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00004-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00005-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00006-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "       part-00007-dd993f19-406b-40a0-be6d-3dc66e17596a-c000.snappy.parquet\n",
      "    products.csv\n",
      "    transactions.csv\n",
      "    transactions_stream\n",
      "        .part-00000-21310585-368a-40ec-bbc6-5bf613e2efa3-c000.snappy.parquet.crc\n",
      "        .part-00000-35b9733c-e02e-43c4-9656-0126a41ca239-c000.snappy.parquet.crc\n",
      "        .part-00000-7dbbd5f7-4bd0-44b1-bc77-e40ca443c53e-c000.snappy.parquet.crc\n",
      "        _spark_metadata\n",
      "        part-00000-21310585-368a-40ec-bbc6-5bf613e2efa3-c000.snappy.parquet\n",
      "        part-00000-35b9733c-e02e-43c4-9656-0126a41ca239-c000.snappy.parquet\n",
      "        part-00000-7dbbd5f7-4bd0-44b1-bc77-e40ca443c53e-c000.snappy.parquet\n",
      " checkpoints\n",
      "    transactions_bronze\n",
      "        .metadata.crc\n",
      "        commits\n",
      "        metadata\n",
      "        offsets\n",
      "        sources\n",
      " gold\n",
      "    dim_customer\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00001-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00002-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00003-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00004-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00005-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00006-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00007-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00010-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00013-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       .part-00015-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00001-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00002-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00003-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00004-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00005-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00006-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00007-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00010-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00013-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "       part-00015-5484704f-29a4-4ad8-bb8e-64665c1f6927-c000.snappy.parquet\n",
      "    dim_customer.csv\n",
      "    dim_date\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00001-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00002-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00003-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00004-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00005-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00006-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       .part-00007-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00001-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00002-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00003-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00004-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00005-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00006-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "       part-00007-97bac1fa-428f-4632-8bd2-9864ad85fcde-c000.snappy.parquet\n",
      "    dim_date.csv\n",
      "    dim_product\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00001-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00002-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00003-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00004-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00005-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00006-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       .part-00007-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00001-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00002-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00003-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00004-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00005-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00006-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "       part-00007-2cdb8ebc-b99a-4f1c-ae8e-17128e79fdbc-c000.snappy.parquet\n",
      "    dim_product.csv\n",
      "    fact_sales\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet.crc\n",
      "       .part-00001-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet.crc\n",
      "       .part-00002-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet\n",
      "       part-00001-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet\n",
      "       part-00002-a540fa02-8a87-413c-a914-30d924a053a1-c000.snappy.parquet\n",
      "    fact_sales.csv\n",
      " silver\n",
      "    customers\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00001-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00002-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00003-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00004-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00005-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00006-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00007-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00010-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00013-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       .part-00015-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00001-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00002-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00003-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00004-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00005-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00006-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00007-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00010-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00013-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "       part-00015-a0a0db4c-eedf-4317-8157-13a7b8288ae7-c000.snappy.parquet\n",
      "    customers.csv\n",
      "    products\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00001-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00002-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00003-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00004-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00005-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00006-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       .part-00007-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00001-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00002-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00003-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00004-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00005-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00006-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "       part-00007-53d90a37-1426-4e5d-b4b9-49d560bd2a78-c000.snappy.parquet\n",
      "    products.csv\n",
      "    transactions\n",
      "       ._SUCCESS.crc\n",
      "       .part-00000-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet.crc\n",
      "       .part-00001-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet.crc\n",
      "       .part-00002-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet.crc\n",
      "       _SUCCESS\n",
      "       part-00000-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet\n",
      "       part-00001-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet\n",
      "       part-00002-03ed1430-4803-41a2-b68f-45bdd58d7139-c000.snappy.parquet\n",
      "    transactions.csv\n",
      " source_transactions.csv\n",
      " streaming\n",
      "    transactions\n",
      "        batch1.json\n",
      "        batch2.json\n",
      "        batch3.json\n",
      " streaming_source\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def show_directory_structure(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Display directory structure\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = sorted(os.listdir(path))\n",
    "        for i, item in enumerate(items):\n",
    "            item_path = os.path.join(path, item)\n",
    "            is_last = i == len(items) - 1\n",
    "            \n",
    "            connector = \" \" if is_last else \" \"\n",
    "            print(f\"{prefix}{connector}{item}\")\n",
    "            \n",
    "            if os.path.isdir(item_path) and not item.startswith('.'):\n",
    "                extension = \"    \" if is_last else \"   \"\n",
    "                show_directory_structure(item_path, prefix + extension, max_depth, current_depth + 1)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "print(\"\\n DATA LAKEHOUSE DIRECTORY STRUCTURE:\")\n",
    "print(\"=\"*80)\n",
    "print(BASE_DIR)\n",
    "show_directory_structure(BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.0. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spark session stopped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.stop()\n",
    "print(\" Spark session stopped\")\n",
    "\n",
    "\n",
    "# import shutil\n",
    "# shutil.rmtree(BASE_DIR)\n",
    "# print(f\" Cleaned up {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Project Documentation\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "This project implements a dimensional data lakehouse following the medallion architecture:\n",
    "\n",
    "**Bronze Layer (Raw):**\n",
    "- Ingests data from multiple heterogeneous sources\n",
    "- Preserves original data format and structure\n",
    "- Serves as the single source of truth\n",
    "\n",
    "**Silver Layer (Cleansed):**\n",
    "- Data cleansing and standardization\n",
    "- Joins streaming fact data with static reference dimensions\n",
    "- Business key matching and data quality validation\n",
    "- Currency conversion using real-time exchange rates\n",
    "\n",
    "**Gold Layer (Business-Level Aggregates):**\n",
    "- Star schema dimensional model\n",
    "- Optimized for business intelligence queries\n",
    "- Contains: dim_date, dim_customer, dim_product, fact_sales\n",
    "\n",
    "### Data Integration Pattern\n",
    "\n",
    "This solution implements an **ELT (Extract-Load-Transform)** pattern:\n",
    "1. **Extract**: Data pulled from MySQL, MongoDB, CSV files, and REST API\n",
    "2. **Load**: Raw data loaded into Bronze layer without transformation\n",
    "3. **Transform**: PySpark transformations applied progressively through Silver to Gold\n",
    "\n",
    "### Streaming Architecture\n",
    "\n",
    "The streaming component follows a **Lambda Architecture** approach:\n",
    "- **Batch Layer**: Static reference data (customers, products, exchange rates)\n",
    "- **Speed Layer**: Real-time transaction data via Spark Structured Streaming\n",
    "- **Serving Layer**: Joined data in Silver/Gold for immediate query access\n",
    "\n",
    "### Business Value\n",
    "\n",
    "The dimensional model enables key business analyses:\n",
    "- **Customer Analytics**: Identify high-value customers and purchasing patterns\n",
    "- **Product Performance**: Track best-selling items and category trends\n",
    "- **Time-Series Analysis**: Monitor sales trends over time (daily, monthly, quarterly)\n",
    "- **Geographic Insights**: Understand regional market performance\n",
    "- **Revenue Metrics**: Calculate KPIs like average order value and customer lifetime value\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
